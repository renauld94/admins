{
  "metadata": {
    "job_title": "Senior Data Engineer",
    "company": "Databricks",
    "job_id": "demo_databricks_001",
    "generated_at": "2025-11-10T06:33:35.036817",
    "match_score": 22.22222222222222,
    "keywords": {
      "required": [
        "GCP",
        "Kafka",
        "Distributed Systems",
        "Spark",
        "Data Pipeline",
        "AWS",
        "Machine Learning",
        "SQL",
        "Python"
      ],
      "preferred": [],
      "technologies": [
        "GCP",
        "Kafka",
        "Distributed Systems",
        "Spark",
        "Data Pipeline",
        "AWS",
        "Machine Learning",
        "SQL",
        "Python"
      ],
      "seniority": "senior"
    }
  },
  "header": {
    "name": "Simon Renauld",
    "title": "Senior Data Engineer & Analytics Professional",
    "email": "contact@simondatalab.de",
    "phone": "+84 (preferred LinkedIn)",
    "linkedin": "linkedin.com/in/simonrenauld",
    "location": "Ho Chi Minh City, Vietnam (Willing to relocate to Australia)"
  },
  "summary": "15+ years data engineering, analytics, and platform architecture. Specialized in GCP, Kafka, Distributed Systems. Proven track record building scalable systems, leading teams, and delivering business impact. Seeking challenging role in innovative organization.",
  "core_skills": {
    "languages": [
      "SQL",
      "Python",
      "Scala",
      "Java",
      "Go",
      "Rust"
    ],
    "data_platforms": [
      "Apache Spark",
      "Apache Airflow",
      "Apache Kafka",
      "Flink",
      "Hive",
      "Presto"
    ],
    "cloud": [
      "AWS (EC2, S3, RDS, Redshift, Lambda, EMR)",
      "GCP (Dataflow, BigQuery)",
      "Azure (Databricks, Data Factory)"
    ],
    "databases": [
      "PostgreSQL",
      "MySQL",
      "MongoDB",
      "Cassandra",
      "Redis",
      "DynamoDB",
      "Snowflake"
    ],
    "big_data": [
      "Hadoop",
      "Hbase",
      "Pig",
      "Mahout",
      "Druid",
      "Elasticsearch"
    ],
    "ml_frameworks": [
      "TensorFlow",
      "PyTorch",
      "Scikit-learn",
      "XGBoost",
      "LightGBM"
    ],
    "tools": [
      "Git",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "Terraform",
      "Ansible",
      "Jupyter",
      "DBT"
    ],
    "soft_skills": [
      "Leadership",
      "Team Building",
      "Mentoring",
      "Project Management",
      "Cross-functional Collaboration"
    ]
  },
  "experience": [
    {
      "title": "Senior Data Engineer",
      "company": "Tech Company A",
      "duration": "2020-2023",
      "highlights": [
        "Designed and implemented 100M+ event/day data pipeline using Spark + Kafka + Airflow",
        "Led team of 8 engineers in building real-time analytics platform",
        "Mentored 5 junior engineers; 2 promoted to senior roles"
      ]
    },
    {
      "title": "Data Engineer",
      "company": "Tech Company B",
      "duration": "2017-2020",
      "highlights": [
        "Built ETL pipelines processing 50TB+ daily data",
        "Implemented Kubernetes cluster managing 200+ jobs daily",
        "Designed data warehouse architecture supporting 1000+ concurrent users"
      ]
    },
    {
      "title": "Data Analyst",
      "company": "Tech Company C",
      "duration": "2015-2017",
      "highlights": [
        "Developed 50+ dashboards used by 500+ internal users",
        "Created data models improving forecast accuracy by 25%",
        "Automated 80% of monthly reporting process"
      ]
    }
  ],
  "education": [
    {
      "degree": "B.S. Computer Science",
      "institution": "University Name",
      "year": "2009"
    }
  ],
  "certifications": [
    "AWS Certified Solutions Architect - Professional",
    "Google Cloud Professional Data Engineer",
    "Databricks Certified Associate Data Engineer",
    "Kubernetes Administrator (CKA)"
  ]
}