{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d05efd",
   "metadata": {},
   "source": [
    "# Session 1.13: Context Managers and File I/O\n",
    "\n",
    "## **Essential for Resource Management in PySpark**\n",
    "\n",
    "### **Learning Objectives**\n",
    "By the end of this session, you will:\n",
    "- Understand context managers and the `with` statement\n",
    "- Handle file operations safely in healthcare data processing\n",
    "- Manage resources properly for PySpark applications\n",
    "- Build custom context managers for healthcare workflows\n",
    "\n",
    "---\n",
    "\n",
    "### **Relevance to PySpark**\n",
    "Context managers ensure proper resource cleanup in PySpark applications, preventing memory leaks and connection issues when working with large datasets and external systems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a8858",
   "metadata": {},
   "source": [
    "## 1. Basic File Operations with Context Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96cdae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Create temporary files for demonstration\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Using temporary directory: {temp_dir}\")\n",
    "\n",
    "# Healthcare data for examples\n",
    "patient_data = [\n",
    "    {'id': 'PT001', 'name': 'John Doe', 'age': 45, 'diagnosis': 'Hypertension'},\n",
    "    {'id': 'PT002', 'name': 'Jane Smith', 'age': 32, 'diagnosis': 'Diabetes'},\n",
    "    {'id': 'PT003', 'name': 'Bob Johnson', 'age': 58, 'diagnosis': 'Asthma'}\n",
    "]\n",
    "\n",
    "# Write patient data to JSON file using context manager\n",
    "json_file_path = os.path.join(temp_dir, 'patients.json')\n",
    "\n",
    "# Safe file writing with automatic resource cleanup\n",
    "with open(json_file_path, 'w') as file:\n",
    "    json.dump(patient_data, file, indent=2)\n",
    "    print(f\"Patient data written to {json_file_path}\")\n",
    "\n",
    "# Read the file back\n",
    "with open(json_file_path, 'r') as file:\n",
    "    loaded_data = json.load(file)\n",
    "    print(f\"\\nLoaded {len(loaded_data)} patient records:\")\n",
    "    for patient in loaded_data:\n",
    "        print(f\"  {patient['id']}: {patient['name']}, {patient['age']} years old\")\n",
    "\n",
    "# Write CSV file\n",
    "csv_file_path = os.path.join(temp_dir, 'patients.csv')\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['id', 'name', 'age', 'diagnosis'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(patient_data)\n",
    "    print(f\"\\nCSV data written to {csv_file_path}\")\n",
    "\n",
    "# Read CSV file\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    print(\"\\nCSV data read back:\")\n",
    "    for row in reader:\n",
    "        print(f\"  {row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e99626",
   "metadata": {},
   "source": [
    "## 2. Error-Safe File Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_file_read(file_path, file_type='text'):\n",
    "    \"\"\"Safely read files with proper error handling and resource management.\"\"\"\n",
    "    try:\n",
    "        if file_type == 'json':\n",
    "            with open(file_path, 'r') as file:\n",
    "                return {'data': json.load(file), 'status': 'success'}\n",
    "        \n",
    "        elif file_type == 'csv':\n",
    "            with open(file_path, 'r') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                return {'data': list(reader), 'status': 'success'}\n",
    "        \n",
    "        else:  # text file\n",
    "            with open(file_path, 'r') as file:\n",
    "                return {'data': file.read(), 'status': 'success'}\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return {'error': f\"File not found: {file_path}\", 'status': 'error'}\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {'error': f\"Invalid JSON format: {e}\", 'status': 'error'}\n",
    "    except PermissionError:\n",
    "        return {'error': f\"Permission denied: {file_path}\", 'status': 'error'}\n",
    "    except Exception as e:\n",
    "        return {'error': f\"Unexpected error: {e}\", 'status': 'error'}\n",
    "\n",
    "def safe_file_write(file_path, data, file_type='json'):\n",
    "    \"\"\"Safely write files with proper error handling and resource management.\"\"\"\n",
    "    try:\n",
    "        if file_type == 'json':\n",
    "            with open(file_path, 'w') as file:\n",
    "                json.dump(data, file, indent=2)\n",
    "        \n",
    "        elif file_type == 'csv':\n",
    "            if not data:\n",
    "                return {'error': 'No data to write', 'status': 'error'}\n",
    "            \n",
    "            with open(file_path, 'w', newline='') as file:\n",
    "                fieldnames = data[0].keys() if isinstance(data[0], dict) else data[0]\n",
    "                writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                if isinstance(data[0], dict):\n",
    "                    writer.writerows(data)\n",
    "        \n",
    "        else:  # text file\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.write(str(data))\n",
    "        \n",
    "        return {'message': f\"Data written to {file_path}\", 'status': 'success'}\n",
    "    \n",
    "    except PermissionError:\n",
    "        return {'error': f\"Permission denied: {file_path}\", 'status': 'error'}\n",
    "    except Exception as e:\n",
    "        return {'error': f\"Error writing file: {e}\", 'status': 'error'}\n",
    "\n",
    "# Test safe file operations\n",
    "print(\"Testing Safe File Operations:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test reading existing file\n",
    "result = safe_file_read(json_file_path, 'json')\n",
    "print(f\"Reading existing JSON: {result['status']}\")\n",
    "print(f\"Records loaded: {len(result.get('data', []))}\")\n",
    "\n",
    "# Test reading non-existent file\n",
    "result = safe_file_read('/nonexistent/file.json', 'json')\n",
    "print(f\"\\nReading non-existent file: {result['status']}\")\n",
    "print(f\"Error: {result.get('error')}\")\n",
    "\n",
    "# Test writing to new file\n",
    "new_data = [{'id': 'PT004', 'name': 'Alice Brown', 'age': 28, 'diagnosis': 'Migraine'}]\n",
    "new_file_path = os.path.join(temp_dir, 'new_patients.json')\n",
    "result = safe_file_write(new_file_path, new_data, 'json')\n",
    "print(f\"\\nWriting new file: {result['status']}\")\n",
    "print(f\"Message: {result.get('message')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fd8b7",
   "metadata": {},
   "source": [
    "## 3. Custom Context Managers for Healthcare Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9faae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "@contextmanager\n",
    "def healthcare_audit_log(operation_name, patient_id=None):\n",
    "    \"\"\"Context manager for auditing healthcare data operations.\"\"\"\n",
    "    start_time = datetime.now()\n",
    "    print(f\"[AUDIT] Starting {operation_name}\" + \n",
    "          (f\" for patient {patient_id}\" if patient_id else \"\") + \n",
    "          f\" at {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    try:\n",
    "        yield  # Execute the code block\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        print(f\"[AUDIT] Completed {operation_name} successfully in {duration:.2f}s\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        print(f\"[AUDIT] Failed {operation_name} after {duration:.2f}s: {e}\")\n",
    "        raise  # Re-raise the exception\n",
    "\n",
    "@contextmanager\n",
    "def patient_data_session(patient_id):\n",
    "    \"\"\"Context manager for patient data processing sessions.\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Opening patient data session for: {patient_id}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    session_data = {\n",
    "        'patient_id': patient_id,\n",
    "        'start_time': datetime.now(),\n",
    "        'operations': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        yield session_data\n",
    "    \n",
    "    finally:\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - session_data['start_time']).total_seconds()\n",
    "        print(f\"\\nSession Summary:\")\n",
    "        print(f\"Patient ID: {patient_id}\")\n",
    "        print(f\"Duration: {duration:.2f} seconds\")\n",
    "        print(f\"Operations performed: {len(session_data['operations'])}\")\n",
    "        for op in session_data['operations']:\n",
    "            print(f\"  - {op}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "\n",
    "class HealthcareDataProcessor:\n",
    "    \"\"\"Healthcare data processor with context manager support.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_directory):\n",
    "        self.data_directory = data_directory\n",
    "        self.active_connections = []\n",
    "    \n",
    "    def __enter__(self):\n",
    "        print(f\"Initializing Healthcare Data Processor\")\n",
    "        print(f\"Data directory: {self.data_directory}\")\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        print(f\"Cleaning up Healthcare Data Processor\")\n",
    "        # Clean up any active connections\n",
    "        for conn in self.active_connections:\n",
    "            print(f\"  Closing connection: {conn}\")\n",
    "        self.active_connections.clear()\n",
    "        \n",
    "        if exc_type:\n",
    "            print(f\"  Exception occurred: {exc_type.__name__}: {exc_val}\")\n",
    "        return False  # Don't suppress exceptions\n",
    "    \n",
    "    def process_patient_file(self, file_path):\n",
    "        \"\"\"Process a patient data file.\"\"\"\n",
    "        connection_id = f\"conn_{len(self.active_connections) + 1}\"\n",
    "        self.active_connections.append(connection_id)\n",
    "        \n",
    "        result = safe_file_read(file_path, 'json')\n",
    "        if result['status'] == 'success':\n",
    "            return result['data']\n",
    "        else:\n",
    "            raise Exception(result['error'])\n",
    "\n",
    "# Demonstrate custom context managers\n",
    "print(\"Testing Custom Context Managers:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Using audit log context manager\n",
    "with healthcare_audit_log(\"Patient BMI Calculation\", \"PT001\"):\n",
    "    # Simulate some processing\n",
    "    weight = 75.5\n",
    "    height = 1.75\n",
    "    bmi = weight / (height ** 2)\n",
    "    time.sleep(0.1)  # Simulate processing time\n",
    "    print(f\"  Calculated BMI: {bmi:.2f}\")\n",
    "\n",
    "# Using patient data session\n",
    "with patient_data_session(\"PT002\") as session:\n",
    "    session['operations'].append(\"Load patient demographics\")\n",
    "    time.sleep(0.05)\n",
    "    \n",
    "    session['operations'].append(\"Calculate vital statistics\")\n",
    "    time.sleep(0.05)\n",
    "    \n",
    "    session['operations'].append(\"Generate health report\")\n",
    "    time.sleep(0.05)\n",
    "\n",
    "# Using healthcare data processor\n",
    "with HealthcareDataProcessor(temp_dir) as processor:\n",
    "    try:\n",
    "        data = processor.process_patient_file(json_file_path)\n",
    "        print(f\"Processed {len(data)} patient records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89839fd",
   "metadata": {},
   "source": [
    "## 4. File Processing Pipelines with Context Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fa964",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def batch_file_processor(input_dir, output_dir, operation_name=\"Batch Processing\"):\n",
    "    \"\"\"Context manager for batch file processing operations.\"\"\"\n",
    "    print(f\"Starting {operation_name}\")\n",
    "    print(f\"Input directory: {input_dir}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    stats = {\n",
    "        'files_processed': 0,\n",
    "        'files_failed': 0,\n",
    "        'start_time': datetime.now()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        yield stats\n",
    "    \n",
    "    finally:\n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - stats['start_time']).total_seconds()\n",
    "        print(f\"\\nBatch Processing Summary:\")\n",
    "        print(f\"Operation: {operation_name}\")\n",
    "        print(f\"Duration: {duration:.2f} seconds\")\n",
    "        print(f\"Files processed: {stats['files_processed']}\")\n",
    "        print(f\"Files failed: {stats['files_failed']}\")\n",
    "        success_rate = (stats['files_processed'] / \n",
    "                       (stats['files_processed'] + stats['files_failed']) * 100 \n",
    "                       if (stats['files_processed'] + stats['files_failed']) > 0 else 0)\n",
    "        print(f\"Success rate: {success_rate:.1f}%\")\n",
    "\n",
    "def process_clinical_data_files():\n",
    "    \"\"\"Process multiple clinical data files using context managers.\"\"\"\n",
    "    \n",
    "    # Create multiple sample files\n",
    "    input_dir = os.path.join(temp_dir, 'input')\n",
    "    output_dir = os.path.join(temp_dir, 'output')\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    \n",
    "    # Create sample patient files\n",
    "    sample_files = {\n",
    "        'cardiology_patients.json': [\n",
    "            {'id': 'CD001', 'name': 'Heart Patient 1', 'condition': 'Arrhythmia'},\n",
    "            {'id': 'CD002', 'name': 'Heart Patient 2', 'condition': 'Hypertension'}\n",
    "        ],\n",
    "        'diabetes_patients.json': [\n",
    "            {'id': 'DB001', 'name': 'Diabetes Patient 1', 'hba1c': 7.2},\n",
    "            {'id': 'DB002', 'name': 'Diabetes Patient 2', 'hba1c': 6.8}\n",
    "        ],\n",
    "        'invalid_file.json': \"invalid json content\"\n",
    "    }\n",
    "    \n",
    "    # Write sample files\n",
    "    for filename, content in sample_files.items():\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        if filename == 'invalid_file.json':\n",
    "            with open(file_path, 'w') as f:\n",
    "                f.write(content)  # Write invalid JSON\n",
    "        else:\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump(content, f, indent=2)\n",
    "    \n",
    "    # Process files using batch processor context manager\n",
    "    with batch_file_processor(input_dir, output_dir, \"Clinical Data Transformation\") as stats:\n",
    "        \n",
    "        # Get all JSON files in input directory\n",
    "        json_files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "        \n",
    "        for filename in json_files:\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, f\"processed_{filename}\")\n",
    "            \n",
    "            with healthcare_audit_log(f\"Processing {filename}\"):\n",
    "                try:\n",
    "                    # Read file\n",
    "                    result = safe_file_read(input_path, 'json')\n",
    "                    if result['status'] != 'success':\n",
    "                        raise Exception(result['error'])\n",
    "                    \n",
    "                    data = result['data']\n",
    "                    \n",
    "                    # Transform data (add processing timestamp)\n",
    "                    if isinstance(data, list):\n",
    "                        for record in data:\n",
    "                            if isinstance(record, dict):\n",
    "                                record['processed_at'] = datetime.now().isoformat()\n",
    "                                record['file_source'] = filename\n",
    "                    \n",
    "                    # Write processed file\n",
    "                    write_result = safe_file_write(output_path, data, 'json')\n",
    "                    if write_result['status'] != 'success':\n",
    "                        raise Exception(write_result['error'])\n",
    "                    \n",
    "                    stats['files_processed'] += 1\n",
    "                    print(f\"  Successfully processed {filename}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    stats['files_failed'] += 1\n",
    "                    print(f\"  Failed to process {filename}: {e}\")\n",
    "\n",
    "# Run the clinical data processing pipeline\n",
    "process_clinical_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2d7d0",
   "metadata": {},
   "source": [
    "## 5. Resource Management for Database-like Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442cce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HealthcareDatabase:\n",
    "    \"\"\"Simulated healthcare database with context manager support.\"\"\"\n",
    "    \n",
    "    def __init__(self, db_name):\n",
    "        self.db_name = db_name\n",
    "        self.connection = None\n",
    "        self.transaction = None\n",
    "        self.is_connected = False\n",
    "    \n",
    "    def connect(self):\n",
    "        \"\"\"Simulate database connection.\"\"\"\n",
    "        print(f\"Connecting to healthcare database: {self.db_name}\")\n",
    "        self.connection = f\"connection_to_{self.db_name}\"\n",
    "        self.is_connected = True\n",
    "        return self.connection\n",
    "    \n",
    "    def disconnect(self):\n",
    "        \"\"\"Simulate database disconnection.\"\"\"\n",
    "        if self.is_connected:\n",
    "            print(f\"Disconnecting from healthcare database: {self.db_name}\")\n",
    "            self.connection = None\n",
    "            self.is_connected = False\n",
    "    \n",
    "    def begin_transaction(self):\n",
    "        \"\"\"Simulate beginning a transaction.\"\"\"\n",
    "        if not self.is_connected:\n",
    "            raise Exception(\"Not connected to database\")\n",
    "        print(\"Beginning transaction\")\n",
    "        self.transaction = f\"transaction_{datetime.now().timestamp()}\"\n",
    "    \n",
    "    def commit_transaction(self):\n",
    "        \"\"\"Simulate committing a transaction.\"\"\"\n",
    "        if self.transaction:\n",
    "            print(\"Committing transaction\")\n",
    "            self.transaction = None\n",
    "    \n",
    "    def rollback_transaction(self):\n",
    "        \"\"\"Simulate rolling back a transaction.\"\"\"\n",
    "        if self.transaction:\n",
    "            print(\"Rolling back transaction\")\n",
    "            self.transaction = None\n",
    "    \n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry.\"\"\"\n",
    "        self.connect()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit with proper cleanup.\"\"\"\n",
    "        if self.transaction:\n",
    "            if exc_type:\n",
    "                self.rollback_transaction()\n",
    "            else:\n",
    "                self.commit_transaction()\n",
    "        \n",
    "        self.disconnect()\n",
    "        return False  # Don't suppress exceptions\n",
    "\n",
    "@contextmanager\n",
    "def database_transaction(db):\n",
    "    \"\"\"Context manager for database transactions.\"\"\"\n",
    "    db.begin_transaction()\n",
    "    try:\n",
    "        yield db\n",
    "        db.commit_transaction()\n",
    "    except Exception:\n",
    "        db.rollback_transaction()\n",
    "        raise\n",
    "\n",
    "def simulate_patient_data_operations():\n",
    "    \"\"\"Simulate patient data operations with proper resource management.\"\"\"\n",
    "    \n",
    "    print(\"Demonstrating Database Context Managers:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Successful operation\n",
    "    print(\"\\n1. Successful Database Operation:\")\n",
    "    with HealthcareDatabase(\"patient_records\") as db:\n",
    "        with database_transaction(db):\n",
    "            print(\"  Inserting patient record...\")\n",
    "            time.sleep(0.1)\n",
    "            print(\"  Updating patient vitals...\")\n",
    "            time.sleep(0.1)\n",
    "            print(\"  Operation completed successfully\")\n",
    "    \n",
    "    # Operation with error (transaction rollback)\n",
    "    print(\"\\n2. Database Operation with Error:\")\n",
    "    try:\n",
    "        with HealthcareDatabase(\"patient_records\") as db:\n",
    "            with database_transaction(db):\n",
    "                print(\"  Inserting patient record...\")\n",
    "                time.sleep(0.1)\n",
    "                print(\"  Simulating error...\")\n",
    "                raise Exception(\"Simulated database error\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Caught exception: {e}\")\n",
    "    \n",
    "    # Multiple operations\n",
    "    print(\"\\n3. Multiple Database Operations:\")\n",
    "    with HealthcareDatabase(\"clinical_data\") as db:\n",
    "        # First transaction\n",
    "        with database_transaction(db):\n",
    "            print(\"  Transaction 1: Adding lab results\")\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        # Second transaction\n",
    "        with database_transaction(db):\n",
    "            print(\"  Transaction 2: Updating patient diagnosis\")\n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print(\"  All operations completed\")\n",
    "\n",
    "# Run the database simulation\n",
    "simulate_patient_data_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aed236",
   "metadata": {},
   "source": [
    "## 6. Practice Exercise\n",
    "\n",
    "Create a comprehensive healthcare data processing pipeline using context managers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Healthcare Data ETL Pipeline with Context Managers\n",
    "# Create a pipeline that:\n",
    "# 1. Reads patient data from multiple sources (JSON, CSV)\n",
    "# 2. Validates and transforms the data\n",
    "# 3. Writes results to output files\n",
    "# 4. Maintains audit logs\n",
    "# 5. Handles errors gracefully\n",
    "# 6. Cleans up resources properly\n",
    "\n",
    "# Sample data for the exercise\n",
    "exercise_data = {\n",
    "    'patients.json': [\n",
    "        {'id': 'PT100', 'name': 'Alice Johnson', 'age': 45, 'weight': 65.2, 'height': 1.68},\n",
    "        {'id': 'PT101', 'name': 'Bob Wilson', 'age': 52, 'weight': 78.5, 'height': 1.75},\n",
    "    ],\n",
    "    'vitals.json': [\n",
    "        {'patient_id': 'PT100', 'heart_rate': 72, 'blood_pressure': '120/80', 'temperature': 98.6},\n",
    "        {'patient_id': 'PT101', 'heart_rate': 85, 'blood_pressure': '135/90', 'temperature': 99.1},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# TODO: Create context managers and functions for:\n",
    "# - ETL pipeline management\n",
    "# - Data validation and transformation\n",
    "# - Result aggregation and reporting\n",
    "# - Error handling and logging\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ed18a",
   "metadata": {},
   "source": [
    "## 7. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da7e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f\"Cleaned up temporary directory: {temp_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cleaning up: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f7088",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this session, you learned:\n",
    "- ✅ Basic file operations with context managers\n",
    "- ✅ Error-safe file reading and writing\n",
    "- ✅ Custom context managers for healthcare workflows\n",
    "- ✅ Batch file processing pipelines\n",
    "- ✅ Resource management for database-like operations\n",
    "- ✅ Proper cleanup and error handling\n",
    "- ✅ Essential patterns for PySpark resource management\n",
    "\n",
    "**Next:** Session 1.14 - Iterators and Generators"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
