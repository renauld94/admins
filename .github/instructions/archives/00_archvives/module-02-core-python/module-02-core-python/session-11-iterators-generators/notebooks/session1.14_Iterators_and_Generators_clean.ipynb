{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Session 1.14: Iterators and Generators\n",
    "\n",
    "## **Memory-Efficient Data Processing for PySpark**\n",
    "\n",
    "### **Learning Objectives**\n",
    "By the end of this session, you will:\n",
    "- Understand iterators and the iterator protocol\n",
    "- Create and use generators for memory-efficient processing\n",
    "- Apply iterator patterns to healthcare data processing\n",
    "- Build memory-efficient pipelines essential for PySpark\n",
    "\n",
    "---\n",
    "\n",
    "### **Relevance to PySpark**\n",
    "Iterators and generators are fundamental to PySpark's lazy evaluation and memory-efficient processing of large datasets. Understanding these concepts is crucial for optimizing PySpark transformations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Understanding Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic iterator concepts\n",
    "patient_list = ['PT001', 'PT002', 'PT003', 'PT004']\n",
    "\n",
    "# Creating an iterator from a list\n",
    "patient_iter = iter(patient_list)\n",
    "\n",
    "print(\"Manual iteration using next():\")\n",
    "print(f\"First patient: {next(patient_iter)}\")\n",
    "print(f\"Second patient: {next(patient_iter)}\")\n",
    "print(f\"Third patient: {next(patient_iter)}\")\n",
    "print(f\"Fourth patient: {next(patient_iter)}\")\n",
    "\n",
    "# Attempting to get next after exhaustion\n",
    "try:\n",
    "    print(f\"Fifth patient: {next(patient_iter)}\")\n",
    "except StopIteration:\n",
    "    print(\"Iterator exhausted - no more patients\")\n",
    "\n",
    "# Creating a custom iterator for patient records\n",
    "class PatientRecordIterator:\n",
    "    \"\"\"Iterator for processing patient records one at a time.\"\"\"\n",
    "    \n",
    "    def __init__(self, patient_data):\n",
    "        self.patient_data = patient_data\n",
    "        self.index = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.index >= len(self.patient_data):\n",
    "            raise StopIteration\n",
    "        \n",
    "        patient = self.patient_data[self.index]\n",
    "        self.index += 1\n",
    "        \n",
    "        # Process patient data\n",
    "        processed_patient = {\n",
    "            'id': patient['id'],\n",
    "            'name': patient['name'],\n",
    "            'age': patient['age'],\n",
    "            'bmi': round(patient['weight'] / (patient['height'] ** 2), 2),\n",
    "            'status': 'processed'\n",
    "        }\n",
    "        \n",
    "        return processed_patient\n",
    "\n",
    "# Sample patient data\n",
    "patients = [\n",
    "    {'id': 'PT001', 'name': 'John Doe', 'age': 45, 'weight': 75.5, 'height': 1.75},\n",
    "    {'id': 'PT002', 'name': 'Jane Smith', 'age': 32, 'weight': 62.3, 'height': 1.65},\n",
    "    {'id': 'PT003', 'name': 'Bob Johnson', 'age': 58, 'weight': 88.2, 'height': 1.80},\n",
    "]\n",
    "\n",
    "print(\"\\nUsing custom PatientRecordIterator:\")\n",
    "patient_iterator = PatientRecordIterator(patients)\n",
    "\n",
    "for processed_patient in patient_iterator:\n",
    "    print(f\"Processed: {processed_patient}\")\n",
    "\n",
    "# Built-in functions that work with iterators\n",
    "print(\"\\nUsing built-in functions with iterators:\")\n",
    "ages = [p['age'] for p in patients]\n",
    "age_iter = iter(ages)\n",
    "\n",
    "print(f\"Sum of ages: {sum(age_iter)}\")\n",
    "\n",
    "# Note: iterator is now exhausted\n",
    "age_iter = iter(ages)  # Create new iterator\n",
    "print(f\"Max age: {max(age_iter)}\")\n",
    "\n",
    "age_iter = iter(ages)  # Create new iterator\n",
    "print(f\"Min age: {min(age_iter)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Introduction to Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_bmi_generator(patient_records):\n",
    "    \"\"\"Generator function to calculate BMI for patients lazily.\"\"\"\n",
    "    for patient in patient_records:\n",
    "        try:\n",
    "            weight = patient['weight']\n",
    "            height = patient['height']\n",
    "            bmi = weight / (height ** 2)\n",
    "            \n",
    "            yield {\n",
    "                'id': patient['id'],\n",
    "                'name': patient['name'],\n",
    "                'bmi': round(bmi, 2),\n",
    "                'category': get_bmi_category(bmi)\n",
    "            }\n",
    "        except (KeyError, ZeroDivisionError, TypeError) as e:\n",
    "            print(f\"Error processing patient {patient.get('id', 'unknown')}: {e}\")\n",
    "            continue\n",
    "\n",
    "def get_bmi_category(bmi):\n",
    "    \"\"\"Categorize BMI values.\"\"\"\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif 18.5 <= bmi < 25:\n",
    "        return 'Normal weight'\n",
    "    elif 25 <= bmi < 30:\n",
    "        return 'Overweight'\n",
    "    else:\n",
    "        return 'Obese'\n",
    "\n",
    "# Using the generator\n",
    "print(\"Using BMI Generator:\")\n",
    "bmi_gen = patient_bmi_generator(patients)\n",
    "\n",
    "# Generators are lazy - values are computed on demand\n",
    "for bmi_data in bmi_gen:\n",
    "    print(f\"Patient {bmi_data['id']}: BMI {bmi_data['bmi']} ({bmi_data['category']})\")\n",
    "\n",
    "# Generator expressions (like list comprehensions but lazy)\n",
    "print(\"\\nUsing generator expressions:\")\n",
    "high_bmi_patients = (p for p in patient_bmi_generator(patients) if p['bmi'] > 25)\n",
    "\n",
    "print(\"Patients with high BMI:\")\n",
    "for patient in high_bmi_patients:\n",
    "    print(f\"  {patient['name']}: BMI {patient['bmi']}\")\n",
    "\n",
    "# Memory efficiency demonstration\n",
    "def large_patient_generator(count):\n",
    "    \"\"\"Generate a large number of simulated patient records.\"\"\"\n",
    "    import random\n",
    "    \n",
    "    for i in range(count):\n",
    "        yield {\n",
    "            'id': f'PT{i+1:06d}',\n",
    "            'name': f'Patient {i+1}',\n",
    "            'age': random.randint(18, 90),\n",
    "            'weight': round(random.uniform(50, 120), 1),\n",
    "            'height': round(random.uniform(1.5, 2.0), 2)\n",
    "        }\n",
    "\n",
    "print(\"\\nMemory-efficient processing of large dataset:\")\n",
    "large_dataset = large_patient_generator(10000)\n",
    "\n",
    "# Process only the first 5 patients without loading all 10,000\n",
    "count = 0\n",
    "for patient in large_dataset:\n",
    "    if count >= 5:\n",
    "        break\n",
    "    \n",
    "    bmi = patient['weight'] / (patient['height'] ** 2)\n",
    "    print(f\"  {patient['id']}: Age {patient['age']}, BMI {bmi:.1f}\")\n",
    "    count += 1\n",
    "\n",
    "print(f\"Processed {count} patients without loading all 10,000 into memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Advanced Generator Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clinical_data_pipeline(*generators):\n",
    "    \"\"\"Chain multiple generators for data processing pipeline.\"\"\"\n",
    "    for generator in generators:\n",
    "        for item in generator:\n",
    "            yield item\n",
    "\n",
    "def patient_demographics_generator(patients):\n",
    "    \"\"\"Generate patient demographic information.\"\"\"\n",
    "    for patient in patients:\n",
    "        yield {\n",
    "            'type': 'demographics',\n",
    "            'patient_id': patient['id'],\n",
    "            'data': {\n",
    "                'name': patient['name'],\n",
    "                'age': patient['age'],\n",
    "                'age_group': get_age_group(patient['age'])\n",
    "            }\n",
    "        }\n",
    "\n",
    "def patient_vitals_generator(patients):\n",
    "    \"\"\"Generate patient vital signs.\"\"\"\n",
    "    import random\n",
    "    \n",
    "    for patient in patients:\n",
    "        # Simulate vital signs\n",
    "        yield {\n",
    "            'type': 'vitals',\n",
    "            'patient_id': patient['id'],\n",
    "            'data': {\n",
    "                'heart_rate': random.randint(60, 100),\n",
    "                'blood_pressure': f\"{random.randint(110, 140)}/{random.randint(70, 90)}\",\n",
    "                'temperature': round(random.uniform(97.0, 99.5), 1)\n",
    "            }\n",
    "        }\n",
    "\n",
    "def patient_lab_results_generator(patients):\n",
    "    \"\"\"Generate patient lab results.\"\"\"\n",
    "    import random\n",
    "    \n",
    "    lab_tests = ['Glucose', 'Cholesterol', 'Hemoglobin', 'White Blood Cells']\n",
    "    \n",
    "    for patient in patients:\n",
    "        for test in lab_tests:\n",
    "            yield {\n",
    "                'type': 'lab_result',\n",
    "                'patient_id': patient['id'],\n",
    "                'data': {\n",
    "                    'test_name': test,\n",
    "                    'value': round(random.uniform(50, 200), 1),\n",
    "                    'unit': get_test_unit(test),\n",
    "                    'status': random.choice(['Normal', 'High', 'Low'])\n",
    "                }\n",
    "            }\n",
    "\n",
    "def get_age_group(age):\n",
    "    \"\"\"Categorize patients by age group.\"\"\"\n",
    "    if age < 18:\n",
    "        return 'Pediatric'\n",
    "    elif age < 65:\n",
    "        return 'Adult'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "def get_test_unit(test_name):\n",
    "    \"\"\"Get unit for lab test.\"\"\"\n",
    "    units = {\n",
    "        'Glucose': 'mg/dL',\n",
    "        'Cholesterol': 'mg/dL',\n",
    "        'Hemoglobin': 'g/dL',\n",
    "        'White Blood Cells': 'K/µL'\n",
    "    }\n",
    "    return units.get(test_name, 'units')\n",
    "\n",
    "# Demonstrate generator chaining\n",
    "print(\"Clinical Data Pipeline with Generator Chaining:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Create generators for different data types\n",
    "demographics_gen = patient_demographics_generator(patients[:2])  # Limit for demo\n",
    "vitals_gen = patient_vitals_generator(patients[:2])\n",
    "labs_gen = patient_lab_results_generator(patients[:1])  # Even fewer for lab results\n",
    "\n",
    "# Chain generators together\n",
    "clinical_pipeline = clinical_data_pipeline(demographics_gen, vitals_gen, labs_gen)\n",
    "\n",
    "# Process chained data\n",
    "data_counts = {'demographics': 0, 'vitals': 0, 'lab_result': 0}\n",
    "\n",
    "for clinical_data in clinical_pipeline:\n",
    "    data_type = clinical_data['type']\n",
    "    patient_id = clinical_data['patient_id']\n",
    "    data = clinical_data['data']\n",
    "    \n",
    "    data_counts[data_type] += 1\n",
    "    \n",
    "    print(f\"[{data_type.upper()}] Patient {patient_id}: {data}\")\n",
    "\n",
    "print(f\"\\nData processed: {data_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Generator-Based Data Filtering and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_patients_by_condition(patients, condition_func):\n",
    "    \"\"\"Filter patients based on a condition function.\"\"\"\n",
    "    for patient in patients:\n",
    "        if condition_func(patient):\n",
    "            yield patient\n",
    "\n",
    "def transform_patient_data(patients, transform_func):\n",
    "    \"\"\"Transform patient data using a transformation function.\"\"\"\n",
    "    for patient in patients:\n",
    "        yield transform_func(patient)\n",
    "\n",
    "def aggregate_patient_data(patients, group_by_func, agg_func):\n",
    "    \"\"\"Aggregate patient data by groups.\"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    groups = defaultdict(list)\n",
    "    \n",
    "    # Group patients\n",
    "    for patient in patients:\n",
    "        group_key = group_by_func(patient)\n",
    "        groups[group_key].append(patient)\n",
    "    \n",
    "    # Yield aggregated results\n",
    "    for group_key, group_patients in groups.items():\n",
    "        yield {\n",
    "            'group': group_key,\n",
    "            'count': len(group_patients),\n",
    "            'aggregated_data': agg_func(group_patients)\n",
    "        }\n",
    "\n",
    "# Extended patient dataset for demonstrations\n",
    "extended_patients = [\n",
    "    {'id': 'PT001', 'name': 'John Doe', 'age': 45, 'weight': 75.5, 'height': 1.75, 'condition': 'Hypertension'},\n",
    "    {'id': 'PT002', 'name': 'Jane Smith', 'age': 32, 'weight': 62.3, 'height': 1.65, 'condition': 'Diabetes'},\n",
    "    {'id': 'PT003', 'name': 'Bob Johnson', 'age': 58, 'weight': 88.2, 'height': 1.80, 'condition': 'Hypertension'},\n",
    "    {'id': 'PT004', 'name': 'Alice Brown', 'age': 28, 'weight': 55.8, 'height': 1.62, 'condition': 'Asthma'},\n",
    "    {'id': 'PT005', 'name': 'Charlie Wilson', 'age': 67, 'weight': 82.1, 'height': 1.78, 'condition': 'Diabetes'},\n",
    "]\n",
    "\n",
    "print(\"Generator-Based Data Processing:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Filter: Senior patients (age >= 65)\n",
    "print(\"\\n1. Senior Patients (age >= 65):\")\n",
    "senior_patients = filter_patients_by_condition(\n",
    "    extended_patients, \n",
    "    lambda p: p['age'] >= 65\n",
    ")\n",
    "\n",
    "for patient in senior_patients:\n",
    "    print(f\"  {patient['name']}, {patient['age']} years old\")\n",
    "\n",
    "# Filter: High BMI patients\n",
    "print(\"\\n2. High BMI Patients (BMI > 25):\")\n",
    "high_bmi_patients = filter_patients_by_condition(\n",
    "    extended_patients,\n",
    "    lambda p: (p['weight'] / (p['height'] ** 2)) > 25\n",
    ")\n",
    "\n",
    "for patient in high_bmi_patients:\n",
    "    bmi = patient['weight'] / (patient['height'] ** 2)\n",
    "    print(f\"  {patient['name']}: BMI {bmi:.1f}\")\n",
    "\n",
    "# Transform: Add calculated fields\n",
    "print(\"\\n3. Transform - Add BMI and Age Group:\")\n",
    "enhanced_patients = transform_patient_data(\n",
    "    extended_patients,\n",
    "    lambda p: {\n",
    "        **p,\n",
    "        'bmi': round(p['weight'] / (p['height'] ** 2), 1),\n",
    "        'age_group': get_age_group(p['age']),\n",
    "        'bmi_category': get_bmi_category(p['weight'] / (p['height'] ** 2))\n",
    "    }\n",
    ")\n",
    "\n",
    "enhanced_list = list(enhanced_patients)  # Convert to list for reuse\n",
    "for patient in enhanced_list[:3]:  # Show first 3\n",
    "    print(f\"  {patient['name']}: BMI {patient['bmi']} ({patient['bmi_category']}), {patient['age_group']}\")\n",
    "\n",
    "# Aggregate: Group by condition\n",
    "print(\"\\n4. Aggregate - Group by Medical Condition:\")\n",
    "condition_aggregates = aggregate_patient_data(\n",
    "    enhanced_list,\n",
    "    lambda p: p['condition'],\n",
    "    lambda patients: {\n",
    "        'avg_age': round(sum(p['age'] for p in patients) / len(patients), 1),\n",
    "        'avg_bmi': round(sum(p['bmi'] for p in patients) / len(patients), 1),\n",
    "        'patient_ids': [p['id'] for p in patients]\n",
    "    }\n",
    ")\n",
    "\n",
    "for group in condition_aggregates:\n",
    "    print(f\"  {group['group']}: {group['count']} patients\")\n",
    "    print(f\"    Avg Age: {group['aggregated_data']['avg_age']}\")\n",
    "    print(f\"    Avg BMI: {group['aggregated_data']['avg_bmi']}\")\n",
    "    print(f\"    Patients: {', '.join(group['aggregated_data']['patient_ids'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 5. Generator Pipelines for Large Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_validation_generator(patients):\n",
    "    \"\"\"Validate patient data and yield only valid records.\"\"\"\n",
    "    valid_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for patient in patients:\n",
    "        try:\n",
    "            # Validate required fields\n",
    "            required_fields = ['id', 'name', 'age', 'weight', 'height']\n",
    "            for field in required_fields:\n",
    "                if field not in patient or patient[field] is None:\n",
    "                    raise ValueError(f\"Missing required field: {field}\")\n",
    "            \n",
    "            # Validate data ranges\n",
    "            if not (0 <= patient['age'] <= 150):\n",
    "                raise ValueError(f\"Invalid age: {patient['age']}\")\n",
    "            \n",
    "            if not (20 <= patient['weight'] <= 300):\n",
    "                raise ValueError(f\"Invalid weight: {patient['weight']}\")\n",
    "            \n",
    "            if not (1.0 <= patient['height'] <= 2.5):\n",
    "                raise ValueError(f\"Invalid height: {patient['height']}\")\n",
    "            \n",
    "            valid_count += 1\n",
    "            yield patient\n",
    "        \n",
    "        except (ValueError, TypeError) as e:\n",
    "            error_count += 1\n",
    "            print(f\"Validation error for patient {patient.get('id', 'unknown')}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nValidation summary: {valid_count} valid, {error_count} errors\")\n",
    "\n",
    "def data_enrichment_generator(patients):\n",
    "    \"\"\"Enrich patient data with calculated fields.\"\"\"\n",
    "    for patient in patients:\n",
    "        # Calculate BMI\n",
    "        bmi = patient['weight'] / (patient['height'] ** 2)\n",
    "        \n",
    "        # Enrich patient data\n",
    "        enriched_patient = {\n",
    "            **patient,\n",
    "            'bmi': round(bmi, 2),\n",
    "            'bmi_category': get_bmi_category(bmi),\n",
    "            'age_group': get_age_group(patient['age']),\n",
    "            'processed_timestamp': '2024-01-15T10:30:00Z'  # Simulated timestamp\n",
    "        }\n",
    "        \n",
    "        yield enriched_patient\n",
    "\n",
    "def data_quality_scorer_generator(patients):\n",
    "    \"\"\"Score patient records based on data quality.\"\"\"\n",
    "    for patient in patients:\n",
    "        quality_score = 0\n",
    "        quality_issues = []\n",
    "        \n",
    "        # Check completeness\n",
    "        if patient.get('name', '').strip():\n",
    "            quality_score += 25\n",
    "        else:\n",
    "            quality_issues.append('Empty name')\n",
    "        \n",
    "        # Check age reasonableness\n",
    "        age = patient.get('age', 0)\n",
    "        if 18 <= age <= 100:\n",
    "            quality_score += 25\n",
    "        else:\n",
    "            quality_issues.append(f'Unusual age: {age}')\n",
    "        \n",
    "        # Check BMI reasonableness\n",
    "        bmi = patient.get('bmi', 0)\n",
    "        if 15 <= bmi <= 50:\n",
    "            quality_score += 25\n",
    "        else:\n",
    "            quality_issues.append(f'Unusual BMI: {bmi}')\n",
    "        \n",
    "        # Check data freshness (simulated)\n",
    "        if patient.get('processed_timestamp'):\n",
    "            quality_score += 25\n",
    "        else:\n",
    "            quality_issues.append('No processing timestamp')\n",
    "        \n",
    "        # Add quality information\n",
    "        yield {\n",
    "            **patient,\n",
    "            'quality_score': quality_score,\n",
    "            'quality_grade': get_quality_grade(quality_score),\n",
    "            'quality_issues': quality_issues\n",
    "        }\n",
    "\n",
    "def get_quality_grade(score):\n",
    "    \"\"\"Convert quality score to letter grade.\"\"\"\n",
    "    if score >= 90:\n",
    "        return 'A'\n",
    "    elif score >= 80:\n",
    "        return 'B'\n",
    "    elif score >= 70:\n",
    "        return 'C'\n",
    "    elif score >= 60:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Create a comprehensive data processing pipeline\n",
    "def healthcare_data_processing_pipeline(raw_patient_data):\n",
    "    \"\"\"Complete data processing pipeline using generators.\"\"\"\n",
    "    \n",
    "    # Step 1: Validate data\n",
    "    validated_data = data_validation_generator(raw_patient_data)\n",
    "    \n",
    "    # Step 2: Enrich data\n",
    "    enriched_data = data_enrichment_generator(validated_data)\n",
    "    \n",
    "    # Step 3: Score data quality\n",
    "    quality_scored_data = data_quality_scorer_generator(enriched_data)\n",
    "    \n",
    "    return quality_scored_data\n",
    "\n",
    "# Test data with some invalid records\n",
    "test_patients = [\n",
    "    {'id': 'PT001', 'name': 'John Doe', 'age': 45, 'weight': 75.5, 'height': 1.75},\n",
    "    {'id': 'PT002', 'name': '', 'age': 32, 'weight': 62.3, 'height': 1.65},  # Empty name\n",
    "    {'id': 'PT003', 'name': 'Bob Johnson', 'age': 158, 'weight': 88.2, 'height': 1.80},  # Invalid age\n",
    "    {'id': 'PT004', 'name': 'Alice Brown', 'age': 28, 'weight': 55.8, 'height': 1.62},\n",
    "    {'id': 'PT005', 'name': 'Charlie Wilson', 'age': 67, 'weight': 82.1},  # Missing height\n",
    "]\n",
    "\n",
    "print(\"Healthcare Data Processing Pipeline:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Process data through pipeline\n",
    "processed_pipeline = healthcare_data_processing_pipeline(test_patients)\n",
    "\n",
    "print(\"\\nProcessed Patient Data:\")\n",
    "processed_patients = list(processed_pipeline)\n",
    "\n",
    "for patient in processed_patients:\n",
    "    print(f\"\\nPatient {patient['id']} ({patient['name']})\")\n",
    "    print(f\"  Age: {patient['age']}, BMI: {patient['bmi']} ({patient['bmi_category']})\")\n",
    "    print(f\"  Quality Score: {patient['quality_score']}/100 (Grade: {patient['quality_grade']})\")\n",
    "    if patient['quality_issues']:\n",
    "        print(f\"  Issues: {', '.join(patient['quality_issues'])}\")\n",
    "\n",
    "# Pipeline statistics\n",
    "quality_distribution = {}\n",
    "for patient in processed_patients:\n",
    "    grade = patient['quality_grade']\n",
    "    quality_distribution[grade] = quality_distribution.get(grade, 0) + 1\n",
    "\n",
    "print(f\"\\nQuality Distribution: {quality_distribution}\")\n",
    "avg_quality = sum(p['quality_score'] for p in processed_patients) / len(processed_patients)\n",
    "print(f\"Average Quality Score: {avg_quality:.1f}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 6. Memory Usage Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "def memory_efficient_processing_demo():\n",
    "    \"\"\"Demonstrate memory efficiency of generators vs lists.\"\"\"\n",
    "    \n",
    "    def create_large_patient_list(size):\n",
    "        \"\"\"Create large patient list (memory intensive).\"\"\"\n",
    "        import random\n",
    "        patients = []\n",
    "        for i in range(size):\n",
    "            patients.append({\n",
    "                'id': f'PT{i+1:06d}',\n",
    "                'name': f'Patient {i+1}',\n",
    "                'age': random.randint(18, 90),\n",
    "                'weight': round(random.uniform(50, 120), 1),\n",
    "                'height': round(random.uniform(1.5, 2.0), 2)\n",
    "            })\n",
    "        return patients\n",
    "    \n",
    "    def create_large_patient_generator(size):\n",
    "        \"\"\"Create large patient generator (memory efficient).\"\"\"\n",
    "        import random\n",
    "        for i in range(size):\n",
    "            yield {\n",
    "                'id': f'PT{i+1:06d}',\n",
    "                'name': f'Patient {i+1}',\n",
    "                'age': random.randint(18, 90),\n",
    "                'weight': round(random.uniform(50, 120), 1),\n",
    "                'height': round(random.uniform(1.5, 2.0), 2)\n",
    "            }\n",
    "    \n",
    "    dataset_size = 1000  # Reduced for demo purposes\n",
    "    \n",
    "    print(\"Memory Usage Comparison:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # List approach\n",
    "    print(f\"\\n1. List Approach (loading {dataset_size:,} patients):\")\n",
    "    start_time = time.time()\n",
    "    patient_list = create_large_patient_list(dataset_size)\n",
    "    list_creation_time = time.time() - start_time\n",
    "    list_size = sys.getsizeof(patient_list)\n",
    "    \n",
    "    print(f\"   Creation time: {list_creation_time:.4f} seconds\")\n",
    "    print(f\"   Memory usage: {list_size:,} bytes\")\n",
    "    \n",
    "    # Process first 5 patients from list\n",
    "    start_time = time.time()\n",
    "    processed_count = 0\n",
    "    for patient in patient_list:\n",
    "        if processed_count >= 5:\n",
    "            break\n",
    "        bmi = patient['weight'] / (patient['height'] ** 2)\n",
    "        processed_count += 1\n",
    "    list_processing_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"   Processing time (first 5): {list_processing_time:.6f} seconds\")\n",
    "    \n",
    "    # Generator approach\n",
    "    print(f\"\\n2. Generator Approach (generating {dataset_size:,} patients):\")\n",
    "    start_time = time.time()\n",
    "    patient_generator = create_large_patient_generator(dataset_size)\n",
    "    generator_creation_time = time.time() - start_time\n",
    "    generator_size = sys.getsizeof(patient_generator)\n",
    "    \n",
    "    print(f\"   Creation time: {generator_creation_time:.6f} seconds\")\n",
    "    print(f\"   Memory usage: {generator_size:,} bytes\")\n",
    "    \n",
    "    # Process first 5 patients from generator\n",
    "    start_time = time.time()\n",
    "    processed_count = 0\n",
    "    for patient in patient_generator:\n",
    "        if processed_count >= 5:\n",
    "            break\n",
    "        bmi = patient['weight'] / (patient['height'] ** 2)\n",
    "        processed_count += 1\n",
    "    generator_processing_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"   Processing time (first 5): {generator_processing_time:.6f} seconds\")\n",
    "    \n",
    "    # Comparison\n",
    "    print(f\"\\n3. Comparison:\")\n",
    "    memory_savings = ((list_size - generator_size) / list_size) * 100\n",
    "    print(f\"   Memory savings: {memory_savings:.1f}%\")\n",
    "    print(f\"   List memory / Generator memory: {list_size / generator_size:.1f}x\")\n",
    "    \n",
    "    print(f\"\\n   Key insight: Generator uses constant memory regardless of dataset size!\")\n",
    "    print(f\"   This is crucial for PySpark when processing large datasets.\")\n",
    "\n",
    "memory_efficient_processing_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 7. Practice Exercise\n",
    "\n",
    "Build a memory-efficient clinical trial data processor using generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Clinical Trial Data Processing Pipeline\n",
    "# Build a generator-based pipeline that:\n",
    "# 1. Generates simulated clinical trial participant data\n",
    "# 2. Filters participants based on inclusion criteria\n",
    "# 3. Randomizes participants into treatment groups\n",
    "# 4. Tracks and aggregates trial statistics\n",
    "# 5. Generates progress reports without loading all data into memory\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Sample inclusion criteria for a hypertension trial\n",
    "inclusion_criteria = {\n",
    "    'min_age': 18,\n",
    "    'max_age': 75,\n",
    "    'min_systolic_bp': 140,\n",
    "    'max_systolic_bp': 180,\n",
    "    'required_conditions': ['Hypertension']\n",
    "}\n",
    "\n",
    "# TODO: Create generators for:\n",
    "# 1. participant_data_generator(count) - Generate participant records\n",
    "# 2. eligibility_filter_generator(participants, criteria) - Filter eligible participants\n",
    "# 3. randomization_generator(participants, groups) - Assign treatment groups\n",
    "# 4. trial_statistics_generator(participants) - Generate running statistics\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this session, you learned:\n",
    "- ✅ Iterator protocol and custom iterators\n",
    "- ✅ Generator functions and generator expressions\n",
    "- ✅ Advanced generator patterns and chaining\n",
    "- ✅ Memory-efficient data filtering and transformation\n",
    "- ✅ Generator-based processing pipelines\n",
    "- ✅ Memory usage optimization techniques\n",
    "- ✅ Essential concepts for PySpark's lazy evaluation\n",
    "\n",
    "**Next:** Session 1.15 - String Processing and Text Analysis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
